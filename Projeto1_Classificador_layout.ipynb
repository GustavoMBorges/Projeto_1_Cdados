{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Gustavo Marques Borges \n",
    "\n",
    "Nome: Luiz Eduardo Correa Santoro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re \n",
    "# nltk.download('stopwords') dowlod stopword Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Magazine_Luiza_Final.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'Magazine_Luiza_Final.xlsx'\n",
    "if filename in os.listdir():\n",
    "   print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "   print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@tavaresqq a sua troca deu certo? precisando √©...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>o pessoal da #magazineluiza  ja me conhece de ...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@magazineluiza bom dia, cad√™ o meu retorno da ...</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>oi @magazineluiza o  @luansantana t√° h√° dois m...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@grondinellys @magazineluiza voc√™ s√≥ precisa d...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets      Classifica√ß√£o\n",
       "0  @tavaresqq a sua troca deu certo? precisando √©...  Muito Irrelevante\n",
       "1  o pessoal da #magazineluiza  ja me conhece de ...          Relevante\n",
       "2  @magazineluiza bom dia, cad√™ o meu retorno da ...    Muito Relevante\n",
       "3  oi @magazineluiza o  @luansantana t√° h√° dois m...  Muito Irrelevante\n",
       "4  @grondinellys @magazineluiza voc√™ s√≥ precisa d...        Irrelevante"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename, coverters={'Tweets': str})\n",
    "train['Classifica√ß√£o'] = train['Classifica√ß√£o'].astype('category')\n",
    "train.Classifica√ß√£o.cat.categories = ['Muito Irrelevante','Irrelevante','Nulo','Relevante','Muito Relevante']\n",
    "train.Classifica√ß√£o.cat = pd.Categorical(train.Classifica√ß√£o, categories=['Muito Irrelevante','Irrelevante','Nulo','Relevante','Muito Relevante'], ordered=True)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@tavaresqq a sua troca deu certo? precisando √©...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>oi @magazineluiza o  @luansantana t√° h√° dois m...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>@mateus_didi @americanascom @magazineluiza @re...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>rt @heartilyshawn: ol√°, @magazineluiza o canto...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>@odeiopepino @detalhesslr @americanascom @maga...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>@sandrac58953439 oi, sandra. sabia que agora t...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>743</td>\n",
       "      <td>@magazineluiza oi luciana legal lugar como voc...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>@magazineluiza magalu vc √© muito gostosa</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>@elisavitorio oi. pe√ßo desculpa por isso. üòî me...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>749</td>\n",
       "      <td>@magazineluiza bolsonaro estava certo</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets      Classifica√ß√£o\n",
       "0    @tavaresqq a sua troca deu certo? precisando √©...  Muito Irrelevante\n",
       "3    oi @magazineluiza o  @luansantana t√° h√° dois m...  Muito Irrelevante\n",
       "6    @mateus_didi @americanascom @magazineluiza @re...  Muito Irrelevante\n",
       "12   rt @heartilyshawn: ol√°, @magazineluiza o canto...  Muito Irrelevante\n",
       "14   @odeiopepino @detalhesslr @americanascom @maga...  Muito Irrelevante\n",
       "..                                                 ...                ...\n",
       "741  @sandrac58953439 oi, sandra. sabia que agora t...  Muito Irrelevante\n",
       "743  @magazineluiza oi luciana legal lugar como voc...  Muito Irrelevante\n",
       "744           @magazineluiza magalu vc √© muito gostosa  Muito Irrelevante\n",
       "747  @elisavitorio oi. pe√ßo desculpa por isso. üòî me...  Muito Irrelevante\n",
       "749              @magazineluiza bolsonaro estava certo  Muito Irrelevante\n",
       "\n",
       "[315 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtra_Train_MI = train['Classifica√ß√£o'] == 'Muito Irrelevante'\n",
    "Train_MI = train.loc[filtra_Train_MI,:] \n",
    "filtra_Train_I = train['Classifica√ß√£o'] == 'Irrelevante'\n",
    "Train_I = train.loc[filtra_Train_I,:]\n",
    "filtra_Train_N = train['Classifica√ß√£o'] == 'Nulo'\n",
    "Train_N = train.loc[filtra_Train_N,:]\n",
    "filtra_Train_R = train['Classifica√ß√£o'] == 'Relevante'\n",
    "Train_R = train.loc[filtra_Train_R,:]\n",
    "filtra_Train_MR = train['Classifica√ß√£o'] == 'Muito Relevante'\n",
    "Train_MR = train.loc[filtra_Train_MR,:]\n",
    "Train = [Train_MI,Train_I,Train_N,Train_R,Train_MR]\n",
    "Train_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@magazineluiza aquele que eh quero twr e nao t...</td>\n",
       "      <td>Nulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@teeeeeeiii @magazineluiza kkkkk o cora√ß√£o qua...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@onofrifernando oi! te chamei no dm da uma olh...</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@felliperadama @americanascom @magazineluiza @...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@robrtplant @magazineluiza bom dia! informamos...</td>\n",
       "      <td>Nulo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets      Classifica√ß√£o\n",
       "0  @magazineluiza aquele que eh quero twr e nao t...               Nulo\n",
       "1  @teeeeeeiii @magazineluiza kkkkk o cora√ß√£o qua...        Irrelevante\n",
       "2  @onofrifernando oi! te chamei no dm da uma olh...  Muito Irrelevante\n",
       "3  @felliperadama @americanascom @magazineluiza @...        Irrelevante\n",
       "4  @robrtplant @magazineluiza bom dia! informamos...               Nulo"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test['Classifica√ß√£o'] = test['Classifica√ß√£o'].astype('category')\n",
    "test.Classifica√ß√£o.cat.categories = ['Muito Irrelevante','Irrelevante','Nulo','Relevante','Muito Relevante']\n",
    "test.Classifica√ß√£o.cat = pd.Categorical(test.Classifica√ß√£o, categories=['Muito Irrelevante','Irrelevante','Nulo','Relevante','Muito Relevante'], ordered=True)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtra_Test_MI = test['Classifica√ß√£o'] == 'Muito Irrelevante'\n",
    "Test_MI = test.loc[filtra_Test_MI,:] \n",
    "filtra_Test_I = train['Classifica√ß√£o'] == 'Irrelevante'\n",
    "Test_I = test.loc[filtra_Test_I,:]\n",
    "filtra_Test_N = train['Classifica√ß√£o'] == 'Nulo'\n",
    "Test_N = test.loc[filtra_Test_N,:]\n",
    "filtra_Test_R = train['Classifica√ß√£o'] == 'Relevante'\n",
    "Test_R = train.loc[filtra_Test_R,:]\n",
    "filtra_Test_MR = train['Classifica√ß√£o'] == 'Muito Relevante'\n",
    "Test_MR = test.loc[filtra_Test_MR,:]\n",
    "Test = [Test_I,Test_MI,Test_N,Test_R,Test_MR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Nosso produto √© a **Magazine Luiza**, uma empresa varejista de eletr√¥nicos e im√≥veis. Possui lojas f√≠sicas, mas tem maior notoriedade em sua plataforma digital, cujas cr√≠ticas e elogios est√£o fortemente presente na conta do Tweeter da empresa.\n",
    "\n",
    "Para a classifica√ß√£o dos tweets envolvendo a Magazine Luiza, consideramos:\n",
    "   * **‚Äúmuito relevantes‚Äù** aqueles que possuem problemas ou elogios √† marca, detalhando o motivo de sua cr√≠tica \n",
    "   * **‚Äúrelevantes‚Äù** os menos detalhados.\n",
    "   * **‚ÄúNulo‚Äù** s√£o aqueles que demandam cupons de desconto para a marca e tweets com respostas √† pr√≥pria marca, que aparecem, na maioria das vezes, sem contexto. \n",
    "   * **‚Äúirrelevantes‚Äù** foram os coment√°rios ofensivos, que mostravam indigna√ß√£o com a marca, mas utilizando apenas palavras de baixo cal√£o.\n",
    "   * **‚ÄúMuito irrelevante‚Äù** foi marcado para os tweets que a pr√≥pria marca fazia, respondendo os clientes ou para os tweets que n√£o tinham nada a ver com a marca tampouco com o que ela prop√µe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a funcao para tratar os dados \n",
    "def cleanup(tweet):\n",
    "    #cria uma lista para a lista de palavaras filtradas\n",
    "    tweet_limpo = []\n",
    "    #definicao dos metodos de tratamento do dataframe\n",
    "    punctuation = '[@!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese') \n",
    "    text_subbed = re.sub(pattern, '', tweet)\n",
    "    #Limpa stopwords\n",
    "    token_words = TweetTokenizer().tokenize(text_subbed)\n",
    "    for word in token_words:\n",
    "        if word not in stopwords:\n",
    "            tweet_limpo.append(word)\n",
    "    return tweet_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpa os tweets de acordo com  a sua relevancia \n",
    "Train_Limpo = []\n",
    "for dataframe in Train:\n",
    "    lista_de_tweets = dataframe['Tweets'].values.tolist() \n",
    "    lista_tweets_limpos =[]\n",
    "    for tweet in lista_de_tweets:\n",
    "        train_TwL = cleanup(tweet)\n",
    "        lista_tweets_limpos.extend(train_TwL)\n",
    "    Train_Limpo.append(lista_tweets_limpos)\n",
    "    \n",
    "#Caucula e aloca em variavel a probabibidade de ser relevante\n",
    "prob_Re = train['Classifica√ß√£o'].value_counts(True, sort=False)\n",
    "P_MI = prob_Re[0]\n",
    "P_I = prob_Re[1]\n",
    "P_N = prob_Re[2]\n",
    "P_R = prob_Re[3]\n",
    "P_MR = prob_Re[4]\n",
    "\n",
    "P_Re = [P_MI,P_I,P_N,P_R,P_MR]\n",
    "\n",
    "#Separo as listas provevineites dos dataframes\n",
    "palavras_train_MI = pd.Series(Train_Limpo[0]).value_counts().to_dict()\n",
    "palavras_train_I = pd.Series(Train_Limpo[1]).value_counts().to_dict()\n",
    "palavras_train_N = pd.Series(Train_Limpo[2]).value_counts().to_dict()\n",
    "palavras_train_R = pd.Series(Train_Limpo[3]).value_counts().to_dict()\n",
    "palavras_train_MR = pd.Series(Train_Limpo[4]).value_counts().to_dict()\n",
    "\n",
    "\n",
    "dic_Fa_palavras=[palavras_train_MI, palavras_train_I,palavras_train_N,palavras_train_R,palavras_train_MR] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes(tweet):\n",
    "    clean_tweet = cleanup(tweet)\n",
    "    serie_de_fa =[]\n",
    "    for dic in dic_Fa_palavras:\n",
    "        dic_f ={}\n",
    "        for palavra in clean_tweet:\n",
    "            if palavra in dic:\n",
    "                dic_f[palavra] = dic[palavra]\n",
    "            if palavra not in dic:\n",
    "                dic_f[palavra] = 0\n",
    "        serie_de_fa.append(pd.Series(dic_f))\n",
    "        \n",
    "    fa_palavras_MI = serie_de_fa[0]\n",
    "    fa_palavras_I = serie_de_fa[1]\n",
    "    fa_palavras_N = serie_de_fa[2]\n",
    "    fa_palavras_R = serie_de_fa[3]\n",
    "    fa_palavras_MR = serie_de_fa[4]\n",
    "    fa_palavras_Re = [fa_palavras_MI,fa_palavras_I,fa_palavras_N,fa_palavras_R,fa_palavras_MR]  \n",
    "    lista_prob = []\n",
    "    alpha = 0.001\n",
    "    j = 0\n",
    "    for i in fa_palavras_Re:\n",
    "        contagem_palavra_mais_alpha = i.add(alpha)\n",
    "        contagem_todas_palavras = i.sum()\n",
    "        laplace_smothing = contagem_palavra_mais_alpha.divide(contagem_todas_palavras + alpha*(i.size))\n",
    "        smoothing = np.log10(laplace_smothing)\n",
    "        P_palavras_dado_Re = smoothing.sum()\n",
    "        lista_prob.append(P_palavras_dado_Re + (np.log10(P_Re[j])))\n",
    "        j+=1\n",
    "    MAX = 0\n",
    "    for k in range(0,len(lista_prob)):\n",
    "        if lista_prob[k] >= lista_prob[MAX]:\n",
    "            MAX = k\n",
    "    if MAX == 0:\n",
    "        Relevancia_NV = 'Muito Irrelevante'\n",
    "    if MAX == 1:\n",
    "        Relevancia_NV = 'Irrelevante'\n",
    "    if MAX == 2:\n",
    "        Relevancia_NV = 'Nulo'\n",
    "    if MAX == 3:\n",
    "        Relevancia_NV = 'Relevante'\n",
    "    if MAX == 4:\n",
    "        Relevancia_NV = 'Muito Relevante'\n",
    "\n",
    "    return Relevancia_NV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_NaiveBayes = []\n",
    "for i in train['Tweets']:\n",
    "    Cat_NaiveBayes.append(Naive_Bayes(i))\n",
    "train['Relevancia_NB'] = Cat_NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Relevancia_NB</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Muito Irrelevante</th>\n",
       "      <th>Muito Relevante</th>\n",
       "      <th>Nulo</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Muito Irrelevante</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.414993</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>0.160643</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Nulo</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.100402</td>\n",
       "      <td>0.004016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Relevante</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Muito Relevante</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Relevancia_NB      Irrelevante  Muito Irrelevante  Muito Relevante      Nulo  \\\n",
       "Classifica√ß√£o                                                                  \n",
       "Muito Irrelevante     0.002677           0.414993         0.001339  0.001339   \n",
       "Irrelevante           0.160643           0.017403         0.001339  0.002677   \n",
       "Nulo                  0.001339           0.001339         0.001339  0.100402   \n",
       "Relevante             0.000000           0.001339         0.005355  0.002677   \n",
       "Muito Relevante       0.000000           0.000000         0.093708  0.000000   \n",
       "\n",
       "Relevancia_NB      Relevante  \n",
       "Classifica√ß√£o                 \n",
       "Muito Irrelevante   0.001339  \n",
       "Irrelevante         0.001339  \n",
       "Nulo                0.004016  \n",
       "Relevante           0.183400  \n",
       "Muito Relevante     0.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Relevancia_NB_X_Classificacao = pd.crosstab(train.Classifica√ß√£o,train.Relevancia_NB,normalize=True)\n",
    "Relevancia_NB_X_Classificacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A proporcao de acerto do nossvo classificador eh 76.171%\n"
     ]
    }
   ],
   "source": [
    "print(f'A proporcao de acerto do nossvo classificador eh {(Relevancia_NB_X_Classificacao.iloc[1,0]+Relevancia_NB_X_Classificacao.iloc[0,1]+Relevancia_NB_X_Classificacao.iloc[4,3]+Relevancia_NB_X_Classificacao.iloc[3,3]+Relevancia_NB_X_Classificacao.iloc[3,4])*100:.5g}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
